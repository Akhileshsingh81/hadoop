We have a 12 months contract as Hadoop Solutions Architect 

Location - Jersey City, New Jersey

JD - 
 
Work with business units globally to accelerate development of Hadoop and Spark based solutions upon the Client Data Fabric
 
Roles & Responsibilites
 Design high throughput and streaming data pipelines using Client LambdaArchitecture; Internal bulk sources to include server logs, file uploads, database logs, relational sources and CDC; streaming sources to include websockets, HTTP client callbacks, and kafka events
Work with business and applications teams to identify policies relative to data privacy, confidentiality, archiving, retention, etc. and design solution components to operationalize the data the policies
Design and build data provisioning components to deliver data for operational analytics as well as research purposes
Design ultra-low latency micro services to serve data from the State Container within10 milliseconds
Build data pipelines using HDFS, MapReduce, Spark, Storm, Kafka and emerging computer framework
Design Parquet structures for Analytics Containers to serve business intelligence and analytics use cases
Design schema and streaming pipelines for real-time stores such as Cassandra and Hbase
 
Minimum Qualifications
Qualifications
 
• 8+ years hands-on senior developer/architect
 
• 3+ years experience across multiple Hadoop / Spark technologies such as Hadoop, MapReduce, HDFS, Cassandra, HBase, Hive, Flume, Sqoop, Spark, Kafka, etc.
 
• 1+ year experience working with native MapReduce and/or spark
 
• 5+ years Java development background
 
• 5+ years data engineering/ETL development experience working with data at scale
 
• Desired- Bachelor's degree in Computer Science, Engineering or related discipline
 
• Desired- experience with metadata based or rules driven ETL layer
 
• Desired- Experience with development of generic data ingestion and transformation framework



Regards,

Akhilesh Singh,
Recruitment Consultant,
Crowdstaffing
+14083357166
